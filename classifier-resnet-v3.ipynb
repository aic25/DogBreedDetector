{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advanced CNN structure can be used to classify a dogs breed based on its picture. However, training an entire advanced CNN structures take time. One approach to save time is to use a pretrained model whose training set includes sufficient dog data. For this I chose `ResNet50` with weights trained on `ImageNet1000` dataset. I replaced the top two layers of `ResNet50` with a Global Average Pooling layer and a softmax layer with `120` nodes. These layers are then fine tuned to detect dog breeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import GPUtil\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline  \n",
    "\n",
    "# In a multi GPU server, chose which to use:\n",
    "NUMBER_OF_GPUS_TO_USE = 1\n",
    "Availability=GPUtil.getAvailability(GPUtil.getGPUs())\n",
    "all_gpus = np.arange(3)\n",
    "available_gpu_indexes = [x for x in all_gpus if Availability[x]]\n",
    "# Set CUDA_DEVICE_ORDER so the IDs assigned by CUDA match those from nvidia-smi\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# Set CUDA_VISIBLE_DEVICES to mask out all other GPUs than the first NUMBER_OF_GPUS_TO_USE available device id\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(np.array(available_gpu_indexes[:NUMBER_OF_GPUS_TO_USE]).astype(str))\n",
    "\n",
    "import tensorflow as tf\n",
    "config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, random\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path, expand=True):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    if expand:\n",
    "        return np.expand_dims(x, axis=0)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the image is actually a dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ResNet50 model\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))\n",
    "\n",
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/notebooks/Practice/imgnet-dogbreed/Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_files(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data.pop('target_names')\n",
    "_ = data.pop('DESCR')\n",
    "_ = data.pop('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "test_files = []\n",
    "train_targets = []\n",
    "test_targets = []\n",
    "for dog_breed in data_frame.target.value_counts().index:\n",
    "    # take 10% of the images for each class as test set to ensure same “distribution” of train and test set\n",
    "    train_files_tmp, test_files_tmp, train_targets_tmp, test_targets_tmp = train_test_split(data_frame[data_frame.target == dog_breed].filenames.values, data_frame[data_frame.target == dog_breed].target.values, test_size=0.1)\n",
    "    train_files.append(train_files_tmp)\n",
    "    test_files.append(test_files_tmp)\n",
    "    train_targets.append(train_targets_tmp)\n",
    "    test_targets.append(test_targets_tmp)\n",
    "train_files = np.concatenate(train_files[:])\n",
    "test_files = np.concatenate(test_files[:])\n",
    "train_targets = np.concatenate(train_targets[:])\n",
    "test_targets = np.concatenate(test_targets[:])\n",
    "train_targets = np_utils.to_categorical(np.array(train_targets), 120)\n",
    "test_targets = np_utils.to_categorical(np.array(test_targets), 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 120 total dog categories.\n",
      "There are 20580 total dog images.\n",
      "\n",
      "There are 18470 training dog images.\n",
      "There are 2110 test dog images.\n"
     ]
    }
   ],
   "source": [
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(data_frame.target.value_counts()))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use data augmentation to increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    \"\"\"Crops a random region of width x height from image.\n",
    "    Returns an image\"\"\"\n",
    "    ratio = 0.8\n",
    "    width = int(image.shape[1] * ratio)\n",
    "    height = int(image.shape[0] * ratio)\n",
    "    crop_origin_x = np.random.randint(0, image.shape[0] - width)\n",
    "    crop_origin_y = np.random.randint(0, image.shape[1] - height)\n",
    "    cropped_image = image[crop_origin_y:crop_origin_y+height,crop_origin_x:crop_origin_x+width,:]\n",
    "    cropped_image = cv2.resize(cropped_image,(image.shape[0],image.shape[1]))\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and configure augmented image generator\n",
    "datagen_train = ImageDataGenerator(preprocessing_function=random_crop,\n",
    "                                   rotation_range=45,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen_test = ImageDataGenerator() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images for ResNet50\n",
    "processed_train_files = preprocess_input(paths_to_tensor(train_files))\n",
    "processed_test_files = preprocess_input(paths_to_tensor(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = np.load('ResNet50/train_targets.npy')\n",
    "test_targets = np.load('ResNet50/test_targets.npy')\n",
    "\n",
    "train_files = np.load('ResNet50/train_files.npy')\n",
    "test_files = np.load('ResNet50/test_files.npy')\n",
    "\n",
    "processed_train_files = np.load('ResNet50/processed_train_files.npy')\n",
    "processed_test_files = np.load('ResNet50/processed_test_files.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit augmented image generator on data\n",
    "datagen_train.fit(processed_train_files)\n",
    "datagen_test.fit(processed_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(224, 224, 3))\n",
    "# The ResNet50 model that is used to obtain bottleneck features\n",
    "model_resnet = ResNet50(weights='imagenet', include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    input_tensor=input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow = datagen_train.flow(processed_train_files, train_targets, shuffle=True, batch_size=1000)\n",
    "test_flow = datagen_test.flow(processed_test_files, test_targets, shuffle=False, batch_size=len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model with transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define architecture.\n",
    "Resnet50_model = Sequential()\n",
    "Resnet50_model.add(GlobalAveragePooling2D(input_shape=(7, 7, 2048)))\n",
    "Resnet50_model.add(Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 245,880\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and set checkpoints\n",
    "Resnet50_model.compile(optimizer=keras.optimizers.Nadam(),\n",
    "                  loss=keras.losses.categorical_crossentropy,\n",
    "                  metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "temp_id = id_generator()\n",
    "os.makedirs('ResNet50/'+temp_id)\n",
    "checkpointer_resnet = ModelCheckpoint(filepath='ResNet50/'+temp_id+'/weights.best.ResNet50.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "tb = keras.callbacks.TensorBoard(log_dir='./logs/'+temp_id, histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model.\n",
    "for x,y in train_flow:    \n",
    "    history = Resnet50_model.fit(model_resnet.predict(x), y, epochs=5, callbacks=[checkpointer_resnet, tb], validation_split=.1, verbose=0)\n",
    "    if history.history['val_categorical_accuracy'][0] > .9:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "test_features = model_resnet.predict(processed_test_files)\n",
    "\n",
    "### Calculate classification accuracy on the test dataset.\n",
    "predictions = np.argmax(Resnet50_model.predict(test_features), axis=1)\n",
    "actual = np.argmax(test_targets, axis=1)\n",
    "# Report test accuracy\n",
    "test_accuracy = 100*np.sum(predictions==actual)/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ResNet50/train_targets', train_targets)\n",
    "np.save('ResNet50/test_targets', test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ResNet50/train_files',train_files)\n",
    "np.save('ResNet50/test_files',test_files)\n",
    "\n",
    "np.save('ResNet50/processed_train_files', processed_train_files)\n",
    "np.save('ResNet50/processed_test_files', processed_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
